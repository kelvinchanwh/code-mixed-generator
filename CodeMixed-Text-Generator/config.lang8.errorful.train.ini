[GENERAL]
# verbose output
; verbose = 
# source language; default = CHINESE
language_1 = CHINESE
# target language; default = ENGLISH (Must have a suitable parser)
language_2 = ENGLISH
# choose which stages of the pipeline are going to be run; default = pregcm, gcm
# stages_to_run = translate, aligner, pregcm, gcm
stages_to_run = aligner, pregcm
# stages_to_run = pregcm, gcm
# stages_to_run = gcm
# whether to run the pregcm and gcm stages parallely; default = 0 ; set to 1 to run parellely
; parallel_run = 
# path of input directory where input files are present; default = data
input_loc = data/corpus/parallel
# path for output directory; default = data
output_loc = data/corpus/parallel

[TRANSLATE]
# source language code; default = EN
language_1 = EN
# target language code; default = ZH-TW
language_2 = ZH-TW
# name of input file with non-english data; default = hi-to-en-input_lang1
source_inp_file = lang8.errorful.train.tgt.en.txt
# name of output file with english data; default = hi-to-en-input_lang2
target_op_file = lang8.errorful.train.tgt.zh.txt

[ALIGNER]
# name of input file with non-english data; default = hi-to-en-input_lang1
source_inp_file = lang8.errorful.train.tgt.zh.p1.txt
# name of file with english data; default = hi-to-en-input_lang2
target_inp_file = lang8.errorful.train.tgt.en.p1.txt
# name of output file with non-english data; default = hi-to-en-input_lang1
source_op_file = lang8.errorful.train.token.zh.p1.txt
# name of output file with english data; default = hi-to-en-input_lang2
target_op_file = lang8.errorful.train.token.en.p1.txt
# name of pfms file if present; if not given a pfms file will be generated with default name using initials of the two languages, example for hindi and english = hi-to-en_pfms.txt
pfms_file = 
# name of pfms output file for saving output pfms
output_pfms_file = lang8.errorful.train.en.zh.p1.pfms.txt
# name of output file for saving parallel alignments; default = hi-to-en-input_parallel_alignments
align_op_file =lang8.errorful.train.en.zh.p1.alignment.txt
# which aligner to use for generating alignments; default=fast_align Option: awesome_align
aligner_type = awesome_align

[PREGCM]
# path for directory to store output of pregcm stage, this directory will be saved as a sub-directory of the output_loc. if not given then a directory name using initials of the two languages will be used, example for hindi and english = hi-to-en/ inside output_loc directory.
pregcm_output_loc = lang8-errorful-train-en-zh-p1
# cut-off value for pfms score
max_pfms = 
# select the parser to be used from available parsers - stanford and benepar; default = benepar
parser =

[GCM]
# directory that contains output of the pregcm; default = data/hi-to-en
gcm_input_loc = lang8-errorful-train-en-zh
# path for directory to store output of gcm stage, this directory will be saved as a sub-directory of the output_loc. if not given then a directory name using initials of the two languages will be used, example for hindi and english = hi-to-en-gcm/ inside output_loc directory.
gcm_output_loc = lang8-errorful-train-en-zh-gcm
# max number of sentences to generate per sentence, set -1 for getting all the generations; default = 5
k = 1
# which theory to choose for generating cm sentences 'ec' (ec theory) or 'ml' (ml theory); default ec
linguistic_theory = ml
# number of processes for GCM (max value: num of CPU) (defaults to -1: num_cpu())
num_procs = 8

[OUTPUT]
# language tag at word level in each output code-mixed sentence; default 0
lid_output = 1
# visualize dfas that were used to make generations; default 0
dfa_output = 0
# sampling technique to use - random or spf; default = random
sampling = spf
# file name of the input rcm file which is needed for spf sampling; default is rcm_lang_tagged.txt
rcm_file = 

[WEB]
# value of your azure token that will be used to generate translations using azure api
azure_subscription_key = 

